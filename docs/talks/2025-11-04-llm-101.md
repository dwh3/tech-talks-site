---
title: "Intro to Gradient Boosting"
date: 2025-08-12
time: "12:00â€“13:00"
timezone: "America/New_York"
speaker:
  - name: "Jane Doe"
    title: "Senior Data Scientist"
    org: "NYSIF"
level: "Beginner"
tags: ["ml", "python", "trees"]
video:
  type: "youtube"
  id: "dQw4w9WgXcQ"
resources:
  slides: "../slides/gbt.pdf"
  notebook: "../notebooks/gbt.ipynb"
  repo: "https://github.com/<ORG>/gbt-demo"
---

# Intro to Gradient Boosting

[![Open in Colab](https://colab.research.googleusercontent.com/assets/colab-badge.svg)](https://colab.research.google.com/github/<ORG>/tech-talks-site/blob/main/docs/notebooks/gbt.ipynb)

## Slides & Resources
- ðŸ“‘ [Slides (PDF)](../slides/gbt.pdf)
- ðŸ““ [Notebook (.ipynb)](../notebooks/gbt.ipynb)
- ðŸ§© [Code Repo](https://github.com/<ORG>/gbt-demo)

## Recording
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/dQw4w9WgXcQ"
title="YouTube video" frameborder="0"
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Abstract
A gentle introduction to gradient boosted decision trees, covering the biasâ€“variance tradeoff,
learning rate, max depth, estimators, and regularization.

## Outline
1. What is boosting?
2. Additive modeling and loss
3. Key hyperparameters
4. Short demo
